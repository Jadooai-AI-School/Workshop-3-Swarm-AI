{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Install Dependencies:**"
      ],
      "metadata": {
        "id": "SGpw3_rRvJQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install git+https://github.com/openai/swarm.git\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC4ou7MSzIS8",
        "outputId": "0c2f1fdf-defd-4a68-febb-dbf96547e517"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.4/69.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m218.7/218.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.0/99.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for swarm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F1PgAK3Y2iix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**openai client calling grow model**"
      ],
      "metadata": {
        "id": "dvUak49d2in1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from google.colab import userdata\n",
        "#model = \"meta/llama-3.1-405b-instruct\"\n",
        "#model = \"llama-3.1-70b-versatile\"\n",
        "model = \"llama-3.2-90b-text-preview\"\n",
        "\n",
        "model1 = \"llama3-groq-70b-8192-tool-use-preview\"\n",
        "\n",
        "llm_client = openai.OpenAI(\n",
        "  base_url=\"https://api.groq.com/openai/v1\",\n",
        "  api_key=userdata.get('GROQ_API_KEY'),\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "qFZsiK2uzMZT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating agents and functions:**"
      ],
      "metadata": {
        "id": "UI8zCbxx2tKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from swarm import Agent\n",
        "\n",
        "\n",
        "def process_refund(item_id, reason=\"NOT SPECIFIED\"):\n",
        "    \"\"\"Refund an item. Refund an item. Make sure you have the item_id of the form item_... Ask for user confirmation before processing the refund.\"\"\"\n",
        "    print(f\"[mock] Refunding item {item_id} because {reason}...\")\n",
        "    return \"Success!\"\n",
        "\n",
        "\n",
        "def apply_discount():\n",
        "    \"\"\"Apply a discount to the user's cart.\"\"\"\n",
        "    print(\"[mock] Applying discount...\")\n",
        "    return \"Applied discount of 11%\"\n",
        "\n",
        "\n",
        "triage_agent = Agent(\n",
        "    name=\"Triage Agent\",\n",
        "    instructions=\"Determine which agent is best suited to handle the user's request, and transfer the conversation to that agent.\",\n",
        "    model=model1,\n",
        "    tool_choice=\"auto\",\n",
        "    max_turns=2\n",
        ")\n",
        "sales_agent = Agent(\n",
        "    name=\"Sales Agent\",\n",
        "    instructions=\"Be super enthusiastic about selling bees.\",\n",
        "    model=model,\n",
        "    tool_choice=\"auto\",\n",
        "    max_turns=2\n",
        ")\n",
        "refunds_agent = Agent(\n",
        "    name=\"Refunds Agent\",\n",
        "    instructions=\"Help the user with a refund. If the reason is that it was too expensive, offer the user a refund code. If they insist, then process the refund.\",\n",
        "    functions=[process_refund, apply_discount],\n",
        "    model=model,\n",
        "    tool_choice=\"auto\",\n",
        "    max_turns=2\n",
        ")\n",
        "\n",
        "\n",
        "def transfer_back_to_triage(**kwargs):\n",
        "    \"\"\"Call this function if a user is asking about a topic that is not handled by the current agent.\"\"\"\n",
        "    return triage_agent\n",
        "\n",
        "\n",
        "def transfer_to_sales(**kwargs):\n",
        "    return sales_agent\n",
        "\n",
        "\n",
        "def transfer_to_refunds(**kwargs):\n",
        "    return refunds_agent\n",
        "\n",
        "\n",
        "triage_agent.functions = [transfer_to_sales, transfer_to_refunds]\n",
        "sales_agent.functions.append(transfer_back_to_triage)\n",
        "refunds_agent.functions.append(transfer_back_to_triage)"
      ],
      "metadata": {
        "id": "6Ocp7OrCxWoV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "refunds_agent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Gdgb_qNlvIv",
        "outputId": "c892958e-337b-43c7-9d5a-905ac074d9cb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Agent(name='Refunds Agent', model='llama-3.2-90b-text-preview', instructions='Help the user with a refund. If the reason is that it was too expensive, offer the user a refund code. If they insist, then process the refund.', functions=[<function process_refund at 0x7bd201fcd5a0>, <function apply_discount at 0x7bd201fcd630>, <function transfer_back_to_triage at 0x7bd201fcd6c0>], tool_choice='auto', parallel_tool_calls=True)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "triage_agent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhoa29a-l-h3",
        "outputId": "b0f03e04-0b30-4b5d-e76e-9039e042b799"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Agent(name='Triage Agent', model='llama3-groq-70b-8192-tool-use-preview', instructions=\"Determine which agent is best suited to handle the user's request, and transfer the conversation to that agent.\", functions=[<function transfer_to_sales at 0x7bd201fcd750>, <function transfer_to_refunds at 0x7bd201fcd7e0>], tool_choice='auto', parallel_tool_calls=True)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sales_agent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie8zkHVOmAo4",
        "outputId": "21c29b3f-0efb-4d52-ff32-1de2868ba30d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Agent(name='Sales Agent', model='llama-3.2-90b-text-preview', instructions='Be super enthusiastic about selling bees.', functions=[<function transfer_back_to_triage at 0x7bd201fcd6c0>], tool_choice='auto', parallel_tool_calls=True)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**printing reponse of agents**"
      ],
      "metadata": {
        "id": "pSibuEfN2_HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from swarm import Swarm\n",
        "\n",
        "\n",
        "def process_and_print_streaming_response(response):\n",
        "    content = \"\"\n",
        "    last_sender = \"\"\n",
        "\n",
        "    for chunk in response:\n",
        "        if \"sender\" in chunk:\n",
        "            last_sender = chunk[\"sender\"]\n",
        "\n",
        "        if \"content\" in chunk and chunk[\"content\"] is not None:\n",
        "            if not content and last_sender:\n",
        "                print(f\"\\033[94m{last_sender}:\\033[0m\", end=\" \", flush=True)\n",
        "                last_sender = \"\"\n",
        "            print(chunk[\"content\"], end=\"\", flush=True)\n",
        "            content += chunk[\"content\"]\n",
        "\n",
        "        if \"tool_calls\" in chunk and chunk[\"tool_calls\"] is not None:\n",
        "            for tool_call in chunk[\"tool_calls\"]:\n",
        "                f = tool_call[\"function\"]\n",
        "                name = f[\"name\"]\n",
        "                if not name:\n",
        "                    continue\n",
        "                print(f\"\\033[94m{last_sender}: \\033[95m{name}\\033[0m()\")\n",
        "\n",
        "        if \"delim\" in chunk and chunk[\"delim\"] == \"end\" and content:\n",
        "            print()  # End of response message\n",
        "            content = \"\"\n",
        "\n",
        "        if \"response\" in chunk:\n",
        "            return chunk[\"response\"]\n",
        "\n",
        "\n",
        "def pretty_print_messages(messages) -> None:\n",
        "    for message in messages:\n",
        "        if message[\"role\"] != \"assistant\":\n",
        "            continue\n",
        "\n",
        "        # print agent name in blue\n",
        "        print(f\"\\033[94m{message['sender']}\\033[0m:\", end=\" \")\n",
        "\n",
        "        # print response, if any\n",
        "        if message[\"content\"]:\n",
        "            print(message[\"content\"])\n",
        "\n",
        "        # print tool calls in purple, if any\n",
        "        tool_calls = message.get(\"tool_calls\") or []\n",
        "        if len(tool_calls) > 1:\n",
        "            print()\n",
        "        for tool_call in tool_calls:\n",
        "            f = tool_call[\"function\"]\n",
        "            name, args = f[\"name\"], f[\"arguments\"]\n",
        "            arg_str = json.dumps(json.loads(args)).replace(\":\", \"=\")\n",
        "            print(f\"\\033[95m{name}\\033[0m({arg_str[1:-1]})\")"
      ],
      "metadata": {
        "id": "A9eRTVnMlQWF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**creating run loop**"
      ],
      "metadata": {
        "id": "WsNuEX5B3Mnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4  # to generate unique IDs\n",
        "\n",
        "def run_demo_loop(\n",
        "    starting_agent, context_variables=None, stream=False, debug=False\n",
        ") -> None:\n",
        "    client = Swarm(client=llm_client)\n",
        "    print(\"Starting Groq Swarm CLI ğŸ\")\n",
        "\n",
        "    messages = []\n",
        "    agent = starting_agent\n",
        "\n",
        "    while True:\n",
        "\n",
        "        user_input = input(\"\\033[90mUser\\033[0m: \")\n",
        "        if \"exit\" in user_input:\n",
        "            print(\"Good bye\")\n",
        "            break\n",
        "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        response = client.run(\n",
        "            agent=agent,\n",
        "            messages=messages,\n",
        "            context_variables=context_variables or {},\n",
        "            stream=stream,\n",
        "            debug=debug,\n",
        "            max_turns=2\n",
        "        )\n",
        "\n",
        "        if stream:\n",
        "            response = process_and_print_streaming_response(response)\n",
        "        else:\n",
        "            # Add tool_call_id for tool messages\n",
        "            for msg in response.messages:\n",
        "                if msg.get(\"role\") == \"tool\":\n",
        "                    msg[\"tool_call_id\"] = str(uuid4())  # add a unique ID for each tool call\n",
        "\n",
        "            pretty_print_messages(response.messages)\n",
        "\n",
        "        messages.extend(\n",
        "            [{'role': msg['role'], 'content': msg['content'], 'tool_call_id': msg.get(\"tool_call_id\")} if msg[\"role\"] == \"tool\" else {'role': msg['role'], 'content': msg['content']}\n",
        "             for msg in response.messages]\n",
        "        )\n",
        "        agent = response.agent\n"
      ],
      "metadata": {
        "id": "y_7SNou712KC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**running multi agents**"
      ],
      "metadata": {
        "id": "tnD94QQQ3SQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    run_demo_loop(triage_agent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix40Ox7VqbWy",
        "outputId": "7e9f1d14-abff-453d-e584-99ecf85f09b9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Groq Swarm CLI ğŸ\n",
            "\u001b[90mUser\u001b[0m: I'd like to request a refund for item_12345 because it was too expensive. Can you help me with that?\n",
            "\u001b[94mTriage Agent\u001b[0m: Sure, I can assist you with that. Could you please provide me with your order number and the reason for the refund?\n",
            "\u001b[90mUser\u001b[0m: item_12345\n",
            "\u001b[94mTriage Agent\u001b[0m: \n",
            "\u001b[95mtransfer_to_refunds\u001b[0m(\"kwargs\"= \"item_12345\")\n",
            "\u001b[95mtransfer_to_sales\u001b[0m(\"kwargs\"= \"item_12345\")\n",
            "\u001b[90mUser\u001b[0m: Do you have any discounts available?\n",
            "\u001b[94mSales Agent\u001b[0m: We actually have a special promotion going on right now for our Beekeeper's Delight package. It includes a starter hive, protective clothing, and a queen bee - everything you need to start your beekeeping journey. And, we're offering a 10% discount on all packages purchased this month. Would you like more information on that?\n",
            "\u001b[90mUser\u001b[0m: Can you provide support with my account settings?\n",
            "\u001b[94mSales Agent\u001b[0m: \u001b[95mtransfer_back_to_triage\u001b[0m(\"topic\"= \"account settings\")\n",
            "\u001b[90mUser\u001b[0m: I'd like a refund for an item I bought.\n",
            "\u001b[94mTriage Agent\u001b[0m: Could you please provide me with the order number and the reason for the refund?\n",
            "\u001b[90mUser\u001b[0m: I just want to apply a discount to my current order.\n",
            "\u001b[94mTriage Agent\u001b[0m: \n",
            "\u001b[95mtransfer_to_sales\u001b[0m(\"kwargs\"= \"apply_discount\")\n",
            "\u001b[95mtransfer_to_refunds\u001b[0m(\"kwargs\"= \"process_refund\")\n",
            "\u001b[90mUser\u001b[0m: Can you tell me more about the different types of bees you sell?\n",
            "\u001b[94mRefunds Agent\u001b[0m: <function=transfer_back_to_triage>{\"kwargs\": \"bee_types\"}\n",
            "\u001b[90mUser\u001b[0m: Yes, we offer a bulk discount for orders over 1000 bees. Would you like more information on our bulk pricing?\n",
            "\u001b[94mRefunds Agent\u001b[0m: No I'd like to just delete the order and get the refund for item_12345.\n",
            "\u001b[90mUser\u001b[0m:  What other products do you recommend along with bees?\n",
            "\u001b[94mRefunds Agent\u001b[0m: \u001b[95mtransfer_back_to_triage\u001b[0m(\"kwargs\"= \"beekeeping_products\")\n",
            "\u001b[90mUser\u001b[0m: I received my item, but it's too expensive for me. Can I get a refund or a discount instead?\n",
            "\u001b[94mTriage Agent\u001b[0m: \n",
            "\u001b[95mtransfer_to_sales\u001b[0m(\"kwargs\"= \"discount\")\n",
            "\u001b[95mtransfer_to_refunds\u001b[0m(\"kwargs\"= \"refund\")\n",
            "\u001b[90mUser\u001b[0m:  Whatâ€™s the process for getting a refund if an item arrived damaged?\n",
            "\u001b[94mRefunds Agent\u001b[0m:  PROCESSING REFUND FOR ITEM item_12345 REASON too_expensive\n",
            "\n",
            "I'm going to go ahead and process the refund for you. \n",
            "\n",
            "Prior to processing, I would also like to offer you a special discount code for 15% off your next purchase.\n",
            "\u001b[90mUser\u001b[0m:  How long does it take to process a refund, and will I get a confirmation once it's done?\"\n",
            "\u001b[94mRefunds Agent\u001b[0m: <function=process_refund>{\"item_id\": \"item_12345\", \"reason\": \"too expensive\"}\n",
            "\u001b[90mUser\u001b[0m:  How long does it take to process a refund, and will I get a confirmation once it's done?\"\n",
            "\u001b[94mRefunds Agent\u001b[0m: It may take 5-7 days to process the refund, and you'll receive a confirmation via email.\n",
            "\u001b[90mUser\u001b[0m: exit\n",
            "Good bye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pz4OsPGnqbaB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env_rag",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}